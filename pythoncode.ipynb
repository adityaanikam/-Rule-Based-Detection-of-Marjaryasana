{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Marjaryasana Pose Detection System"
      ],
      "metadata": {
        "id": "od3OYOvjKjYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zMT7zobQ3OBm",
        "outputId": "87893131-42ca-40db-8fc9-ba2ee715dc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nub4GWC-3EkM"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import cv2\n",
        "from typing import Tuple, Union, List\n",
        "import logging\n",
        "\n",
        "class MarjaryasanaDetector:\n",
        "    def __init__(self):\n",
        "        # Initialize MediaPipe Pose\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=1,\n",
        "            enable_segmentation=False,\n",
        "            min_detection_confidence=0.5\n",
        "        )\n",
        "        # Set up logging\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def calculate_angle(self, point1, point2, point3) -> float:\n",
        "        \"\"\"\n",
        "        Calculate angle between three points.\n",
        "\n",
        "        Args:\n",
        "            point1, point2, point3: MediaPipe landmark points\n",
        "\n",
        "        Returns:\n",
        "            float: Angle in degrees\n",
        "        \"\"\"\n",
        "        try:\n",
        "            a = np.array([point1.x, point1.y])\n",
        "            b = np.array([point2.x, point2.y])\n",
        "            c = np.array([point3.x, point3.y])\n",
        "\n",
        "            ba = a - b\n",
        "            bc = c - b\n",
        "\n",
        "            cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "            angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "\n",
        "            return np.degrees(angle)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating angle: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def get_landmarks(self, results) -> Union[List, None]:\n",
        "        \"\"\"\n",
        "        Extract relevant landmarks from pose detection results.\n",
        "\n",
        "        Args:\n",
        "            results: MediaPipe pose detection results\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing relevant landmark points or None if not found\n",
        "        \"\"\"\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "            return {\n",
        "                'shoulders': [\n",
        "                    landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "                    landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
        "                ],\n",
        "                'hips': [\n",
        "                    landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                    landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
        "                ],\n",
        "                'knees': [\n",
        "                    landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "                    landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
        "                ],\n",
        "                'elbows': [\n",
        "                    landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                    landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
        "                ],\n",
        "                'wrists': [\n",
        "                    landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
        "                    landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
        "                ]\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting landmarks: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def detect_pose(self, image) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Detect if the person is in Marjaryasana pose.\n",
        "\n",
        "        Args:\n",
        "            image: Input image in BGR format\n",
        "\n",
        "        Returns:\n",
        "            tuple: (is_pose_detected: bool, message: str)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert the BGR image to RGB\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Process the image and get pose landmarks\n",
        "            results = self.pose.process(image_rgb)\n",
        "\n",
        "            # Get landmarks\n",
        "            landmark_dict = self.get_landmarks(results)\n",
        "            if landmark_dict is None:\n",
        "                return False, \"No pose detected\"\n",
        "\n",
        "            # Calculate key angles\n",
        "            spine_angle = self.calculate_angle(\n",
        "                landmark_dict['shoulders'][0],\n",
        "                landmark_dict['hips'][0],\n",
        "                landmark_dict['knees'][0]\n",
        "            )\n",
        "\n",
        "            arm_angle = self.calculate_angle(\n",
        "                landmark_dict['shoulders'][0],\n",
        "                landmark_dict['elbows'][0],\n",
        "                landmark_dict['wrists'][0]\n",
        "            )\n",
        "\n",
        "            # Define pose criteria\n",
        "            is_marjaryasana = (\n",
        "                # Spine should be roughly horizontal (parallel to ground)\n",
        "                80 <= spine_angle <= 100 and\n",
        "                # Arms should be straight and perpendicular to ground\n",
        "                160 <= arm_angle <= 180 and\n",
        "                # Check if hands and knees are on ground level (similar y-coordinates)\n",
        "                abs(landmark_dict['wrists'][0].y - landmark_dict['knees'][0].y) < 0.1 and\n",
        "                # Check if hands are shoulder-width apart\n",
        "                abs(landmark_dict['wrists'][0].x - landmark_dict['wrists'][1].x) <=\n",
        "                abs(landmark_dict['shoulders'][0].x - landmark_dict['shoulders'][1].x) * 1.5\n",
        "            )\n",
        "\n",
        "            if is_marjaryasana:\n",
        "                return True, \"Marjaryasana detected\"\n",
        "            else:\n",
        "                return False, \"Not in Marjaryasana pose\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in pose detection: {str(e)}\")\n",
        "            return False, f\"Error detecting pose: {str(e)}\"\n",
        "\n",
        "    def process_video(self, video_path: str, output_path: str = None) -> None:\n",
        "        \"\"\"\n",
        "        Process video file and detect Marjaryasana pose in each frame.\n",
        "\n",
        "        Args:\n",
        "            video_path: Path to input video file\n",
        "            output_path: Optional path for output video file\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            if not cap.isOpened():\n",
        "                raise ValueError(\"Could not open video file\")\n",
        "\n",
        "            if output_path:\n",
        "                frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "                fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "                out = cv2.VideoWriter(output_path,\n",
        "                                    cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                                    fps, (frame_width, frame_height))\n",
        "\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Detect pose\n",
        "                is_pose, message = self.detect_pose(frame)\n",
        "\n",
        "                # Draw status on frame\n",
        "                color = (0, 255, 0) if is_pose else (0, 0, 255)\n",
        "                cv2.putText(frame, message, (50, 50),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "                if output_path:\n",
        "                    out.write(frame)\n",
        "\n",
        "                cv2.imshow('Marjaryasana Detection', frame)\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "            cap.release()\n",
        "            if output_path:\n",
        "                out.release()\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing video: {str(e)}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the detector\n",
        "detector = MarjaryasanaDetector()\n",
        "\n",
        "try:\n",
        "    # For single image\n",
        "    image = cv2.imread('pose.jpg')\n",
        "    if image is None:\n",
        "        raise ValueError(\"Could not read image file\")\n",
        "\n",
        "    is_pose, message = detector.detect_pose(image)\n",
        "    print(message)\n",
        "\n",
        "    # For video\n",
        "    # yoga_video.mp4 is used to for imaging purpose you can add your own file\n",
        "    detector.process_video('yoga_video.mp4', 'output.mp4')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJTtl4H63gXG",
        "outputId": "9c057ee2-5afb-42a0-d0d3-964cc1eb8099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Could not read image file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DeV7LJA6KJ2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}